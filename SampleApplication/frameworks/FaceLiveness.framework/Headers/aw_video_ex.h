/**********************************************************************
 *
 * Copyright (C) 2020 Aware, Inc.
 *
 * $Workfile:  $    $Revision:  $
 * Last Modified: $Date: $ by: $Author:  $
 *
 **********************************************************************/

/* DO NOT EDIT THIS FILE. IT IS AUTO-GENERATED */

#ifndef _AW_VIDEO_H_
#define _AW_VIDEO_H_

#ifdef __IOS__
# include "aw_types.h"
#else
# include "awlib/aw_types.h"
#endif

#if defined(_WIN32)
# include <windows.h>
# ifndef AW_VIDEO_DECLARE
#   if !defined(AW_VIDEO_STATIC_LIBRARY)
#     define AW_VIDEO_DECLARE(rtn) __declspec(dllimport) rtn WINAPI
#   else 
#     define AW_VIDEO_DECLARE(rtn) rtn
#   endif 
# endif
#else /* !_WIN32 */
# ifndef AW_VIDEO_DECLARE
#   define AW_VIDEO_DECLARE(rtn) rtn
# endif
#define HWND int
#define WINAPI 
#endif /* !_WIN32 */

#ifdef __IOS__
# include "aw_preface.h"
#else
# include "aw_preface/aw_preface.h"
#endif


#ifdef __cplusplus
extern "C" {
#endif

typedef struct aw_video_t aw_video_t;

/* The current device status. */
enum aw_video_device_status_t
{
    /* The Camera is physically disconnected or off.  The camera is no
       longer valid.  Refresh the camera list to connect again. */
    AW_VIDEO_DEVICE_STATUS_DISCONNECTED=0,

    /* The Camera is connected and on, but not opened. */
    AW_VIDEO_DEVICE_STATUS_CONNECTED=1,

    /* Camera is open and available for use. */
    AW_VIDEO_DEVICE_STATUS_OPEN=2,

    /* Camera is currently previewing. */
    AW_VIDEO_DEVICE_STATUS_PREVIEWING=3,

    /*  */
    AW_VIDEO_DEVICE_STATUS_CAPTURING=4,

    /* Camera has been set to an unsupported mode.  The camera is no longer
       valid.  Refresh the camera list to connect again. */
    AW_VIDEO_DEVICE_STATUS_UNSUPPORTED_MODE=5
};
typedef enum aw_video_device_status_t aw_video_device_status_t;

/* The supported camera types. */
enum aw_video_camera_type_t
{
    /* An unsupported camera type. */
    AW_VIDEO_CAMERA_TYPE_UNSUPPORTED=0,

    /* Cameras that use DirectX. */
    AW_VIDEO_CAMERA_TYPE_DIRECTX=1,

    /* Canon Cameras that use the EOS SDK. */
    AW_VIDEO_CAMERA_TYPE_EOS=2,

    /* iDS Camera that uses the uEye SDK. */
    AW_VIDEO_CAMERA_TYPE_IDS=3,

    /* Videology Camera that uses DirectX with the Videology SDK (optional) */
    AW_VIDEO_CAMERA_TYPE_VIDEOLOGY=4,

    /* External user camera. */
    AW_VIDEO_CAMERA_TYPE_EXTERNAL=5,

    /* Iris ID iCAM TD100. */
    AW_VIDEO_CAMERA_TYPE_ICAM_TD100=6,

    /* Akiyama Camera that uses the Akiyama Face SDK. */
    AW_VIDEO_CAMERA_TYPE_AKIYAMA=7
};
typedef enum aw_video_camera_type_t aw_video_camera_type_t;

/* Image format. */
enum aw_video_image_format_t
{
    /* Undefined format */
    AW_VIDEO_IMAGE_FORMAT_UNDEFINED=0,

    /* BMP format */
    AW_VIDEO_IMAGE_FORMAT_BMP=2,

    /* JPEG format */
    AW_VIDEO_IMAGE_FORMAT_JPG=4,

    /* Raw RGB 24-bit image format */
    AW_VIDEO_IMAGE_FORMAT_RAW_RGB=11,

    /* Raw BGR 24-bit image format */
    AW_VIDEO_IMAGE_FORMAT_RAW_BGR=20,

    /* Upside-down raw RGB 24-bit format */
    AW_VIDEO_IMAGE_FORMAT_RAW_RGB_INVERTED=21,

    /* Upside-down raw BGR 24-bit format */
    AW_VIDEO_IMAGE_FORMAT_RAW_BGR_INVERTED=22,

    /* Raw ARGB 32-bit image format */
    AW_VIDEO_IMAGE_FORMAT_RAW_ARGB=23,

    /* Raw BGRA 32-bit image format */
    AW_VIDEO_IMAGE_FORMAT_RAW_BGRA=24,

    /* YUV 4:2:0 NV21 format. */
    AW_VIDEO_IMAGE_FORMAT_RAW_NV21=25
};
typedef enum aw_video_image_format_t aw_video_image_format_t;

/*  */
enum aw_video_detection_feedback_t
{
    /* The Liveness Algorithm is currently off. */
    AW_VIDEO_DETECTION_FEEDBACK_OFF=0,

    /* No face was detected in the image provided. */
    AW_VIDEO_DETECTION_FEEDBACK_NO_FACE_DETECTED=1,

    /* Multiple faces were detected in the image provided. */
    AW_VIDEO_DETECTION_FEEDBACK_MULTIPLE_FACES_DETECTED=2,

    /* The current frame rate is too slow to perform liveness detection
       accurately. */
    AW_VIDEO_DETECTION_FEEDBACK_FRAMERATE_TOO_SLOW=3,

    /* Gathering data on subject.  No score is currently available. 
       Querying the score will return -1.0 until SCORES READY feedback. */
    AW_VIDEO_DETECTION_FEEDBACK_GATHERING_DATA=4,

    /* Done gathering data on the subject.  Scores are available to query. */
    AW_VIDEO_DETECTION_FEEDBACK_SCORES_READY=5,

    /* The frame for analysis is invalid. */
    AW_VIDEO_DETECTION_FEEDBACK_INVALID_FRAME=6,

    /* The frame for analysis is invalid due to blur. */
    AW_VIDEO_DETECTION_FEEDBACK_INVALID_FRAME_DUE_TO_BLUR=7,

    /* The frame for analysis is invalid due to low contrast or invalid eye
       detections. */
    AW_VIDEO_DETECTION_FEEDBACK_INVALID_FRAME_DUE_TO_POOR_EYE_DEFINITION=8,

    /* The frame for analysis is invalid due to bright lighting conditions. */
    AW_VIDEO_DETECTION_FEEDBACK_INVALID_FRAME_DUE_TO_LIGHTING=9,

    /* The frame for analysis is invalid due to pose. */
    AW_VIDEO_DETECTION_FEEDBACK_INVALID_FRAME_DUE_TO_POSE=10,

    /* The frame for analysis is invalid due to the presence of glasses. */
    AW_VIDEO_DETECTION_FEEDBACK_INVALID_FRAME_DUE_TO_GLASSES=11
};
typedef enum aw_video_detection_feedback_t aw_video_detection_feedback_t;

/*  */
enum aw_video_face_event_t
{
    /* Detect if the subject is blinking. */
    AW_VIDEO_FACE_EVENT_BLINK=0,

    /* Detect if the subject smiles. */
    AW_VIDEO_FACE_EVENT_SMILE=1,

    /* Detect if the subject is turning to the left. */
    AW_VIDEO_FACE_EVENT_HEAD_TURNED_LEFT=2,

    /* Detect if the subject is turning to the right. */
    AW_VIDEO_FACE_EVENT_HEAD_TURNED_RIGHT=3
};
typedef enum aw_video_face_event_t aw_video_face_event_t;

/* Select in what order faces are detected. */
enum aw_video_face_detection_mode_t
{
    /* Order faces based on size. (Default) */
    AW_VIDEO_FACE_DETECTION_MODE_FACE_ORDERING_BY_SIZE=0,

    /* Order faces based on face size. */
    AW_VIDEO_FACE_DETECTION_MODE_FACE_ORDERING_BY_SCORE=1,

    /* Find a single face with the largest size. */
    AW_VIDEO_FACE_DETECTION_MODE_DOMINANT_FACE_BY_SIZE=2,

    /* Find a single face with the highest face score. */
    AW_VIDEO_FACE_DETECTION_MODE_DOMINANT_FACE_BY_SCORE=3,

    /* Detect the largest face then track it until is no longer detected. 
       When the tracked face is no longer detected, track the next largest
       face. */
    AW_VIDEO_FACE_DETECTION_MODE_LOCKED_FACE_BY_SIZE=5,

    /* Detect the face with the highest face score then track it until it is
       no longer detected.  When the tracked face is no longer detected,
       track the next face with highest score. */
    AW_VIDEO_FACE_DETECTION_MODE_LOCKED_FACE_BY_SCORE=6
};
typedef enum aw_video_face_detection_mode_t aw_video_face_detection_mode_t;

/* Camera white balance value table. */
enum aw_video_white_balance_t
{
    /* Automatic */
    AW_VIDEO_WHITE_BALANCE_AUTO=0,

    /* Daylight */
    AW_VIDEO_WHITE_BALANCE_DAYLIGHT=1,

    /* Cloudy */
    AW_VIDEO_WHITE_BALANCE_CLOUDY=2,

    /* Tungsten */
    AW_VIDEO_WHITE_BALANCE_TUNGSTEN=3,

    /* Fluorescent */
    AW_VIDEO_WHITE_BALANCE_FLUORESCENT=4,

    /* Flash */
    AW_VIDEO_WHITE_BALANCE_FLASH=5,

    /* Manual */
    AW_VIDEO_WHITE_BALANCE_MANUAL=6,

    /* Shade */
    AW_VIDEO_WHITE_BALANCE_SHADE=8,

    /* Color Temperature */
    AW_VIDEO_WHITE_BALANCE_COLOR_TEMP=9,

    /* Custom White Balance PC-1 */
    AW_VIDEO_WHITE_BALANCE_PC_SET_ONE=10,

    /* Custom White Balance PC-2 */
    AW_VIDEO_WHITE_BALANCE_PC_SET_TWO=11,

    /* Custom White Balance PC-3 */
    AW_VIDEO_WHITE_BALANCE_PC_SET_THREE=12,

    /* Manual 2 */
    AW_VIDEO_WHITE_BALANCE_MANUAL_TWO=15,

    /* Manual 3 */
    AW_VIDEO_WHITE_BALANCE_MANUAL_THREE=16,

    /* Manual 4 */
    AW_VIDEO_WHITE_BALANCE_MANUAL_FOUR=18,

    /* Manual 5 */
    AW_VIDEO_WHITE_BALANCE_MANUAL_FIVE=19,

    /* Custom White Balance PC-4 */
    AW_VIDEO_WHITE_BALANCE_PC_SET_FOUR=20,

    /* Custom White Balance PC-5 */
    AW_VIDEO_WHITE_BALANCE_PC_SET_FIVE=21,

    /* Setting White Balance by Clicking Image Coordinates */
    AW_VIDEO_WHITE_BALANCE_CLICK=-1,

    /* White Balance Copied From Another Image */
    AW_VIDEO_WHITE_BALANCE_PASTED=-2,

    /* Xenon Flash */
    AW_VIDEO_WHITE_BALANCE_XENON_FLASH=22,

    /* Halogen */
    AW_VIDEO_WHITE_BALANCE_HALOGEN=23,

    /* Fluorescent H */
    AW_VIDEO_WHITE_BALANCE_FLUORESCENT_H=24
};
typedef enum aw_video_white_balance_t aw_video_white_balance_t;

/* Camera ISO Speed property value table. */
enum aw_video_iso_t
{
    /* ISO Auto */
    AW_VIDEO_ISO_AUTO=0
};
typedef enum aw_video_iso_t aw_video_iso_t;

/* Camera metering mode value table. */
enum aw_video_metering_mode_t
{
    /* Spot Metering */
    AW_VIDEO_METERING_MODE_SPOT=1,

    /* Evaluative Metering */
    AW_VIDEO_METERING_MODE_EVALUATIVE=3,

    /* Partial Metering */
    AW_VIDEO_METERING_MODE_PARTIAL=4,

    /* Center-weighted Averaging Metering */
    AW_VIDEO_METERING_MODE_CENTER_WEIGHTED_AVERAGING=5
};
typedef enum aw_video_metering_mode_t aw_video_metering_mode_t;

/* Canon camera shutter speed value table. */
enum aw_video_shutter_speed_t
{
    /* 1/30 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_30=96,

    /* 1/40 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_40=99,

    /* 1/45 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_45=100,

    /* 1/50 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_50=101,

    /* 1/60 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_60=104,

    /* 1/80 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_80=107,

    /* 1/90 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_90=108,

    /* 1/100 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_100=109,

    /* 1/125 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_125=112,

    /* 1/160 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_160=115,

    /* 1/180 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_180=116,

    /* 1/200 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_200=117,

    /* 1/250 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_250=120,

    /* 1/320 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_320=123,

    /* 1/350 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_350=124,

    /* 1/400 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_400=125,

    /* 1/500 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_500=128,

    /* 1/640 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_640=131,

    /* 1/750 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_750=132,

    /* 1/800 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_800=133,

    /* 1/1000 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_1000=136,

    /* 1/1250 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_1250=139,

    /* 1/1500 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_1500=140,

    /* 1/1600 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_1600=141,

    /* 1/2000 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_2000=144,

    /* 1/2500 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_2500=147,

    /* 1/3000 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_3000=148,

    /* 1/3200 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_3200=149,

    /* 1/4000 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_4000=152,

    /* 1/5000 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_5000=155,

    /* 1/6000 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_6000=156,

    /* 1/6400 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_6400=157,

    /* 1/8000 seconds */
    AW_VIDEO_SHUTTER_SPEED_SS1_8000=160
};
typedef enum aw_video_shutter_speed_t aw_video_shutter_speed_t;

/* Camera properties. */
enum aw_video_camera_property_t
{
    /* Preview image width of the camera.  (Constrained by current Capture
       Resolution setting to valid Preview Resolutions.) */
    AW_VIDEO_CAMERA_PROPERTY_PREVIEW_WIDTH=0,

    /* Preview image height of the camera.  (Constrained by current Capture
       Resolution setting to valid Preview Resolutions.) */
    AW_VIDEO_CAMERA_PROPERTY_PREVIEW_HEIGHT=1,

    /* Capture image width of the camera. */
    AW_VIDEO_CAMERA_PROPERTY_CAPTURE_WIDTH=2,

    /* Capture image height of the camera. */
    AW_VIDEO_CAMERA_PROPERTY_CAPTURE_HEIGHT=3,

    /* Exposure of the camera. */
    AW_VIDEO_CAMERA_PROPERTY_EXPOSURE=4,

    /* Focus of the camera. */
    AW_VIDEO_CAMERA_PROPERTY_FOCUS=5,

    /* Zoom of the camera. */
    AW_VIDEO_CAMERA_PROPERTY_ZOOM=6,

    /* Enable or disable auto exposure settings of the camera. */
    AW_VIDEO_CAMERA_PROPERTY_AUTO_EXPOSURE=7,

    /* Enable or disable auto focus settings of the camera. */
    AW_VIDEO_CAMERA_PROPERTY_AUTO_FOCUS=8,

    /* Enable or disable the camera's light.  Property index 0 for off and
       property index 1 for on. */
    AW_VIDEO_CAMERA_PROPERTY_LIGHT=9,

    /* Flash setting */
    AW_VIDEO_CAMERA_PROPERTY_FLASH=10,

    /* Set or query the clockwise image rotation angle. */
    AW_VIDEO_CAMERA_PROPERTY_ROTATION_ANGLE=11,

    /* Set or query the white balance setting. */
    AW_VIDEO_CAMERA_PROPERTY_WHITE_BALANCE=12,

    /* Set or query the camera ISO speed. */
    AW_VIDEO_CAMERA_PROPERTY_ISO_SPEED=13,

    /* Set or query the camera shutter speed. */
    AW_VIDEO_CAMERA_PROPERTY_SHUTTER_SPEED=14,

    /* Set or query the camera metering mode. */
    AW_VIDEO_CAMERA_PROPERTY_METERING_MODE=15,

    /* Preview image width of the camera. (Not constrained by current
       Capture Resolution setting.  Only used to query device capabilities.) */
    AW_VIDEO_CAMERA_PROPERTY_ALL_PREVIEW_WIDTH=16,

    /* Preview image height of the camera. (Not constrained by current
       capture resolution settings.  Only used to query device
       capabilities.) */
    AW_VIDEO_CAMERA_PROPERTY_ALL_PREVIEW_HEIGHT=17,

    /* When enabled, the camera will stream at the capture resolution
       selected and analyze the images downsampled to the preview
       resolution.  The full sized image is used in AutoCapture to
       immediately return a captured frame instead of switching the camera
       to the capture resolution then taking them image.  This property is
       only available for DirectX cameras.  Property index 0 for off and 1
       for on. */
    AW_VIDEO_CAMERA_PROPERTY_GENERATE_CAPTURE_CANDIDATES=18,

    /* Enable or disable auto white balancing settings of the camera. */
    AW_VIDEO_CAMERA_PROPERTY_AUTO_WHITE_BALANCE=19,

    /* Set or query the camera color temperature setting. */
    AW_VIDEO_CAMERA_PROPERTY_COLOR_TEMPERATURE=20,

    /* Enable or disable automatic color temperature on the camera. */
    AW_VIDEO_CAMERA_PROPERTY_AUTO_COLOR_TEMPERATURE=21
};
typedef enum aw_video_camera_property_t aw_video_camera_property_t;

/* Autocapture analysis mode. */
enum aw_video_autocapture_mode_t
{
    /* Do not run analysis. (Default): */
    AW_VIDEO_AUTOCAPTURE_MODE_OFF=0,

    /* Run analysis and make decisions based on autocapture results. */
    AW_VIDEO_AUTOCAPTURE_MODE_ON=1,

    /* Run analysis but ignore autocapture results. */
    AW_VIDEO_AUTOCAPTURE_MODE_OBSERVER=2
};
typedef enum aw_video_autocapture_mode_t aw_video_autocapture_mode_t;

/* Feedback from the autocapture algorithm. */
enum aw_video_autocapture_feedback_t
{
    /* AutoCapture is off and unconfigured. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_OFF=0,

    /* The image analyzed is compliant with the current profile. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_COMPLIANT_IMAGE=1,

    /* AutoCapture has triggered the capture of an image.  The preview is
       ending. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_CAPTURE_IMAGE=2,

    /* Image resolution is too low to be compliant. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_IMAGE_RESOLUTION_TOO_LOW=3,

    /* No face was detected in the image provided. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_NO_FACE_DETECTED=4,

    /* Multiple faces were detected in the image provided. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_MULTIPLE_FACES_DETECTED=5,

    /* The subject's facial pose is invalid. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_INVALID_POSE=6,

    /* The subject's face is too far from the camera. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_FACE_TOO_FAR=7,

    /* The subject's face is too close to the camera. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_FACE_TOO_CLOSE=8,

    /* The subject's face is too far to the left. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_FACE_ON_LEFT=9,

    /* The subject's face is too far to the right. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_FACE_ON_RIGHT=10,

    /* The subject's face is too high in the frame. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_FACE_TOO_HIGH=11,

    /* The subject's face is too low in the frame. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_FACE_TOO_LOW=12,

    /* The lighting is too dark. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_INSUFFICIENT_LIGHTING=13,

    /* The lighting is too bright. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_LIGHT_TOO_BRIGHT=14,

    /* The camera is out of focus. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_TOO_MUCH_BLUR=15,

    /* The subject is non-compliant due to the presence of eye-wear. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_GLASSES_PRESENT=16,

    /* The subject is non-compliant due to the absence of eye-wear. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_GLASSES_ABSENT=17,

    /* The subject is non-compliant because they are smiling. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_SMILE_PRESENT=18,

    /* The subject is non-compliant because they are not smiling. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_SMILE_ABSENT=19,

    /* The subject's forehead is covered. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_FOREHEAD_COVERING=20,

    /* The background is too cluttered. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_BACKGROUND_TOO_CLUTTERED=21,

    /* The background is too bright. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_BACKGROUND_TOO_BRIGHT=22,

    /* The background is too dark. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_BACKGROUND_TOO_DARK=23,

    /* The subject's gender is non-compliant with the current profile. 
       Gender must be female. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_GENDER_NOT_FEMALE=24,

    /* The subject's gender is non-compliant with the current profile. 
       Gender must be male. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_GENDER_NOT_MALE=25,

    /* The subject's race is non-compliant with the current profile.  Race
       must be White. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_RACE_NOT_WHITE=26,

    /* The subject's race is non-compliant with the current profile. Race
       must be Black. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_RACE_NOT_BLACK=27,

    /* The subject's race is non-compliant with the current profile.  Race
       must be Asian. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_RACE_NOT_ASIAN=28,

    /* The subject's left eye is closed. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_LEFT_EYE_CLOSED=29,

    /* The subject's right eye is closed. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_RIGHT_EYE_CLOSED=30,

    /* The subject's left eye is obstructed. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_LEFT_EYE_OBSTRUCTED=31,

    /* The subject's right eye is obstructed. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_RIGHT_EYE_OBSTRUCTED=32,

    /* The subject's gaze is off angle. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_OFF_ANGLE_GAZE=33,

    /* The subject is non-compliant due to the thickness of their eye-wear
       frames. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_HEAVY_FRAMES=34,

    /* The frame is non-compliant due to excessive glare. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_GLARE=35,

    /* The subject is non-compliant due to the presence of dark glasses. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_DARK_GLASSES=36,

    /* The subject is too young for the current profile. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_TOO_YOUNG=37,

    /* The subject is too old for the current profile. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_TOO_OLD=38,

    /* Shadows detected on the subject's face. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_FACIAL_SHADOWING=39,

    /* Red eye detected for the subject. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_RED_EYE=40,

    /* An unnatural lighting color was detected in the frame. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_UNNATURAL_LIGHTING_COLOR=41,

    /* Internal Error 1 */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_AWARE_INTERNAL_ERROR_1=42,

    /* The subject is non-compliant due to something obfuscating their
       mouth. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_MOUTH_OBSCURED=43,

    /* The analyzed image was within all profile parameter ranges but found
       non-compliant. */
    AW_VIDEO_AUTOCAPTURE_FEEDBACK_UNKNOWN=999
};
typedef enum aw_video_autocapture_feedback_t aw_video_autocapture_feedback_t;

/*  */
enum aw_video_algorithm_t
{
    /*  */
    AW_VIDEO_ALGORITHM_B2=1,

    /*  */
    AW_VIDEO_ALGORITHM_D2=4,

    /*  */
    AW_VIDEO_ALGORITHM_B3=6,

    /*  */
    AW_VIDEO_ALGORITHM_E1=10,

    /*  */
    AW_VIDEO_ALGORITHM_E2=111,

    /*  */
    AW_VIDEO_ALGORITHM_E3=112,

    /*  */
    AW_VIDEO_ALGORITHM_E4=113,

    /*  */
    AW_VIDEO_ALGORITHM_E5=114,

    /*  */
    AW_VIDEO_ALGORITHM_E6=115,

    /*  */
    AW_VIDEO_ALGORITHM_E7=116,

    /*  */
    AW_VIDEO_ALGORITHM_E8=117,

    /*  */
    AW_VIDEO_ALGORITHM_E9=118,

    /*  */
    AW_VIDEO_ALGORITHM_E1_W=119,

    /*  */
    AW_VIDEO_ALGORITHM_E2_W=120,

    /*  */
    AW_VIDEO_ALGORITHM_E3_W=121,

    /*  */
    AW_VIDEO_ALGORITHM_E4_W=122,

    /*  */
    AW_VIDEO_ALGORITHM_E5_W=123,

    /*  */
    AW_VIDEO_ALGORITHM_E6_W=124,

    /*  */
    AW_VIDEO_ALGORITHM_E7_W=125,

    /*  */
    AW_VIDEO_ALGORITHM_E8_W=126,

    /*  */
    AW_VIDEO_ALGORITHM_E9_W=127,

    /*  */
    AW_VIDEO_ALGORITHM_N1=12,

    /*  */
    AW_VIDEO_ALGORITHM_N2=13,

    /*  */
    AW_VIDEO_ALGORITHM_N3=14,

    /*  */
    AW_VIDEO_ALGORITHM_N4=15,

    /*  */
    AW_VIDEO_ALGORITHM_N5=16,

    /*  */
    AW_VIDEO_ALGORITHM_N6=17,

    /*  */
    AW_VIDEO_ALGORITHM_N7=18,

    /*  */
    AW_VIDEO_ALGORITHM_N8=19,

    /*  */
    AW_VIDEO_ALGORITHM_N9=20,

    /*  */
    AW_VIDEO_ALGORITHM_N1_A=21,

    /*  */
    AW_VIDEO_ALGORITHM_N1_B=22,

    /*  */
    AW_VIDEO_ALGORITHM_N1_C=23,

    /*  */
    AW_VIDEO_ALGORITHM_N1_D=24,

    /*  */
    AW_VIDEO_ALGORITHM_N1_E=25,

    /*  */
    AW_VIDEO_ALGORITHM_N1_F=26,

    /*  */
    AW_VIDEO_ALGORITHM_N1_G=27,

    /*  */
    AW_VIDEO_ALGORITHM_N1_H=28,

    /*  */
    AW_VIDEO_ALGORITHM_N1_I=29,

    /*  */
    AW_VIDEO_ALGORITHM_N1_J=30,

    /*  */
    AW_VIDEO_ALGORITHM_N1_W=128,

    /*  */
    AW_VIDEO_ALGORITHM_N2_A=31,

    /*  */
    AW_VIDEO_ALGORITHM_N2_B=32,

    /*  */
    AW_VIDEO_ALGORITHM_N2_C=33,

    /*  */
    AW_VIDEO_ALGORITHM_N2_D=34,

    /*  */
    AW_VIDEO_ALGORITHM_N2_E=35,

    /*  */
    AW_VIDEO_ALGORITHM_N2_F=36,

    /*  */
    AW_VIDEO_ALGORITHM_N2_G=37,

    /*  */
    AW_VIDEO_ALGORITHM_N2_H=38,

    /*  */
    AW_VIDEO_ALGORITHM_N2_I=39,

    /*  */
    AW_VIDEO_ALGORITHM_N2_J=40,

    /*  */
    AW_VIDEO_ALGORITHM_N2_W=129,

    /*  */
    AW_VIDEO_ALGORITHM_N3_A=41,

    /*  */
    AW_VIDEO_ALGORITHM_N3_B=42,

    /*  */
    AW_VIDEO_ALGORITHM_N3_C=43,

    /*  */
    AW_VIDEO_ALGORITHM_N3_D=44,

    /*  */
    AW_VIDEO_ALGORITHM_N3_E=45,

    /*  */
    AW_VIDEO_ALGORITHM_N3_F=46,

    /*  */
    AW_VIDEO_ALGORITHM_N3_G=47,

    /*  */
    AW_VIDEO_ALGORITHM_N3_H=48,

    /*  */
    AW_VIDEO_ALGORITHM_N3_I=49,

    /*  */
    AW_VIDEO_ALGORITHM_N3_J=50,

    /*  */
    AW_VIDEO_ALGORITHM_N3_W=130,

    /*  */
    AW_VIDEO_ALGORITHM_N4_A=51,

    /*  */
    AW_VIDEO_ALGORITHM_N4_B=52,

    /*  */
    AW_VIDEO_ALGORITHM_N4_C=53,

    /*  */
    AW_VIDEO_ALGORITHM_N4_D=54,

    /*  */
    AW_VIDEO_ALGORITHM_N4_E=55,

    /*  */
    AW_VIDEO_ALGORITHM_N4_F=56,

    /*  */
    AW_VIDEO_ALGORITHM_N4_G=57,

    /*  */
    AW_VIDEO_ALGORITHM_N4_H=58,

    /*  */
    AW_VIDEO_ALGORITHM_N4_I=59,

    /*  */
    AW_VIDEO_ALGORITHM_N4_J=60,

    /*  */
    AW_VIDEO_ALGORITHM_N4_W=131,

    /*  */
    AW_VIDEO_ALGORITHM_N5_A=61,

    /*  */
    AW_VIDEO_ALGORITHM_N5_B=62,

    /*  */
    AW_VIDEO_ALGORITHM_N5_C=63,

    /*  */
    AW_VIDEO_ALGORITHM_N5_D=64,

    /*  */
    AW_VIDEO_ALGORITHM_N5_E=65,

    /*  */
    AW_VIDEO_ALGORITHM_N5_F=66,

    /*  */
    AW_VIDEO_ALGORITHM_N5_G=67,

    /*  */
    AW_VIDEO_ALGORITHM_N5_H=68,

    /*  */
    AW_VIDEO_ALGORITHM_N5_I=69,

    /*  */
    AW_VIDEO_ALGORITHM_N5_J=70,

    /*  */
    AW_VIDEO_ALGORITHM_N5_W=132,

    /*  */
    AW_VIDEO_ALGORITHM_N6_A=71,

    /*  */
    AW_VIDEO_ALGORITHM_N6_B=72,

    /*  */
    AW_VIDEO_ALGORITHM_N6_C=73,

    /*  */
    AW_VIDEO_ALGORITHM_N6_D=74,

    /*  */
    AW_VIDEO_ALGORITHM_N6_E=75,

    /*  */
    AW_VIDEO_ALGORITHM_N6_F=76,

    /*  */
    AW_VIDEO_ALGORITHM_N6_G=77,

    /*  */
    AW_VIDEO_ALGORITHM_N6_H=78,

    /*  */
    AW_VIDEO_ALGORITHM_N6_I=79,

    /*  */
    AW_VIDEO_ALGORITHM_N6_J=80,

    /*  */
    AW_VIDEO_ALGORITHM_N6_W=133,

    /*  */
    AW_VIDEO_ALGORITHM_N7_A=81,

    /*  */
    AW_VIDEO_ALGORITHM_N7_B=82,

    /*  */
    AW_VIDEO_ALGORITHM_N7_C=83,

    /*  */
    AW_VIDEO_ALGORITHM_N7_D=84,

    /*  */
    AW_VIDEO_ALGORITHM_N7_E=85,

    /*  */
    AW_VIDEO_ALGORITHM_N7_F=86,

    /*  */
    AW_VIDEO_ALGORITHM_N7_G=87,

    /*  */
    AW_VIDEO_ALGORITHM_N7_H=88,

    /*  */
    AW_VIDEO_ALGORITHM_N7_I=89,

    /*  */
    AW_VIDEO_ALGORITHM_N7_J=90,

    /*  */
    AW_VIDEO_ALGORITHM_N7_W=134,

    /*  */
    AW_VIDEO_ALGORITHM_N8_A=91,

    /*  */
    AW_VIDEO_ALGORITHM_N8_B=92,

    /*  */
    AW_VIDEO_ALGORITHM_N8_C=93,

    /*  */
    AW_VIDEO_ALGORITHM_N8_D=94,

    /*  */
    AW_VIDEO_ALGORITHM_N8_E=95,

    /*  */
    AW_VIDEO_ALGORITHM_N8_F=96,

    /*  */
    AW_VIDEO_ALGORITHM_N8_G=97,

    /*  */
    AW_VIDEO_ALGORITHM_N8_H=98,

    /*  */
    AW_VIDEO_ALGORITHM_N8_I=99,

    /*  */
    AW_VIDEO_ALGORITHM_N8_J=100,

    /*  */
    AW_VIDEO_ALGORITHM_N8_W=135,

    /*  */
    AW_VIDEO_ALGORITHM_N9_A=101,

    /*  */
    AW_VIDEO_ALGORITHM_N9_B=102,

    /*  */
    AW_VIDEO_ALGORITHM_N9_C=103,

    /*  */
    AW_VIDEO_ALGORITHM_N9_D=104,

    /*  */
    AW_VIDEO_ALGORITHM_N9_E=105,

    /*  */
    AW_VIDEO_ALGORITHM_N9_F=106,

    /*  */
    AW_VIDEO_ALGORITHM_N9_G=107,

    /*  */
    AW_VIDEO_ALGORITHM_N9_H=108,

    /*  */
    AW_VIDEO_ALGORITHM_N9_I=109,

    /*  */
    AW_VIDEO_ALGORITHM_N9_J=110,

    /*  */
    AW_VIDEO_ALGORITHM_N9_W=136
};
typedef enum aw_video_algorithm_t aw_video_algorithm_t;

/*  */
enum aw_video_scoring_mode_t
{
    /* Algorithms will return a score based on the previous frame or pair of
       frames. */
    AW_VIDEO_SCORING_MODE_SINGLE=0,

    /* Algorithms will return a score based on the previous several frames. */
    AW_VIDEO_SCORING_MODE_WINDOWED=1,

    /* Algorithms will return a score based on all previous frames.
       (Default) */
    AW_VIDEO_SCORING_MODE_CUMULATIVE=2,

    /* Algorithms will return their raw scores. */
    AW_VIDEO_SCORING_MODE_RAW=3,

    /* Algorithms will return a score based on all previous frames. (Patch
       not applied) */
    AW_VIDEO_SCORING_MODE_CUMULATIVE_NO_PATCH=4
};
typedef enum aw_video_scoring_mode_t aw_video_scoring_mode_t;

/* Frame Meta Data Tags */
enum aw_video_frame_tag_t
{
    /* Frame darkened by external source. */
    AW_VIDEO_FRAME_TAG_DARKENED=0,

    /* Frame brightened by external source. */
    AW_VIDEO_FRAME_TAG_BRIGHTENED=1
};
typedef enum aw_video_frame_tag_t aw_video_frame_tag_t;

struct aw_video_camera_t;
typedef struct aw_video_camera_t aw_video_camera_t;

struct aw_video_external_camera_config_t;
typedef struct aw_video_external_camera_config_t aw_video_external_camera_config_t;

struct aw_video_results_t;
typedef struct aw_video_results_t aw_video_results_t;

/* <Function> aw_video_preview_callback
   <Description> Callback used to send preview frames up to the user.
   <Parameters>
     camera - Camera object.
     results_handle - Results object related to the frame analysis.
     error_code - Error Code.
     private_data - Private data used to determine callback context.
   <Return Value>
     None
    */
typedef void WINAPI aw_video_preview_callback_t(
  aw_video_camera_t* camera,
  aw_video_results_t* results_handle,
  aw_int32_t error_code,
  void* private_data
);

/* <Function> aw_video_capture_callback
   <Description> Callback used to get the capture frame up to the user.
   <Parameters>
     camera - Camera object.
     results_handle - Results object related to the capture frame's analysis.
     error_code - Error code.
     private_data - Private data used to determine callback context.
   <Return Value>
     None
    */
typedef void WINAPI aw_video_capture_callback_t(
  aw_video_camera_t* camera,
  aw_video_results_t* results_handle,
  aw_int32_t error_code,
  void* private_data
);

/* <Function> aw_video_device_status_callback
   <Description> Callback used to send device status up to the user.
   <Parameters>
     camera - Camera object.
     device_status - Device status code.
     private_data - Private data used to determine callback context.
   <Return Value>
     None
    */
typedef void WINAPI aw_video_device_status_callback_t(
  aw_video_camera_t* camera,
  aw_video_device_status_t device_status,
  void* private_data
);

/* Library Management */

/* <Function> aw_video_create
   <Description> This function creates the Cam object.
   <Return Value>
     Pointer to the Cam object, null if the object could not be allocated.
    */
AW_VIDEO_DECLARE(aw_video_t*) aw_video_create();

/* <Function> aw_video_destroy
   <Description> This function destroys the Cam object.
   <Parameters>
     aw_video - Library object pointer.
   <Return Value>
     None
    */
AW_VIDEO_DECLARE(void) aw_video_destroy(
  aw_video_t* aw_video
);

/* Version Functions */

/* <Function> aw_video_get_version
   <Description> Returns integer value indicating the current version of the
   component.
   <Return Value>
     An integer indicating the library version number.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_get_version();

/* <Function> aw_video_get_version_string
   <Description> Returns a text string indicating the current version of the
   component.
   <Return Value>
     A string indicating the library version number.
    */
AW_VIDEO_DECLARE(const aw_char_t*) aw_video_get_version_string();

/* Camera */


/* <Function> aw_video_camera_get_type
   <Description> Get the type of the camera.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
   <Return Value>
     Type of the camera.
    */
AW_VIDEO_DECLARE(aw_video_camera_type_t) aw_video_camera_get_type(
  aw_video_t* aw_video,
  aw_video_camera_t* camera
);

/* <Function> aw_video_camera_get_name
   <Description> Get the name of the camera.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
   <Return Value>
     Name of the camera.
    */
AW_VIDEO_DECLARE(const aw_char_t*) aw_video_camera_get_name(
  aw_video_t* aw_video,
  aw_video_camera_t* camera
);

/* <Function> aw_video_camera_open
   <Description> Opens the camera.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
   <Return Value>
     Status code of the function called.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_open(
  aw_video_t* aw_video,
  aw_video_camera_t* camera
);

/* <Function> aw_video_camera_close
   <Description> Closes the camera.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
   <Return Value>
     Status code of the function called.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_close(
  aw_video_t* aw_video,
  aw_video_camera_t* camera
);

/* <Function> aw_video_camera_get_property_index
   <Description> Gets the current index of the given camera property.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
     prop - Camera property to query.
   <Return Value>
     Index the given camera property is at currently.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_get_property_index(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_video_camera_property_t prop
);

/* <Function> aw_video_camera_set_property_index
   <Description> Sets the index of the given camera property.
                   *Notes*
                   When changing capture resolution index, the
   list of preview resolutions will change.
                   When changing capture resolution to be a
   different aspect ratio or smaller than the current preview
   resolution, the preview resolution index will change to the
   closest value to the new capture resolution.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
     prop - Camera property to set.
     index - Index the given camera property is to be set to. For autofocus,
             index is used as 0 for off, anything else for on.                
                                                          For Canon EOS
             camera, this command is supported by the EOS 50D or EOS 5D Mark
             II or later cameras, and only for preview.
   <Return Value>
     Status code of the function called.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_set_property_index(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_video_camera_property_t prop,
  aw_int32_t index
);

/* <Function> aw_video_camera_get_property_values
   <Description> Get the list of values for the specified camera property.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
     prop - Camera property to query.
     count_size - Size of Values for the specified property.
   <Return Value>
     Values for the specified property.
    */
AW_VIDEO_DECLARE(aw_int32_t*) aw_video_camera_get_property_values(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_video_camera_property_t prop,
  size_t* count_size
);

/* <Function> aw_video_camera_start_preview
   <Description> Starts the preview.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
   <Return Value>
     Status code of the function called.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_start_preview(
  aw_video_t* aw_video,
  aw_video_camera_t* camera
);

/* <Function> aw_video_camera_end_preview
   <Description> Ends the preview.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
   <Return Value>
     Status code of the function called.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_end_preview(
  aw_video_t* aw_video,
  aw_video_camera_t* camera
);

/* <Function> aw_video_camera_get_preview_frame
   <Description> Gets the most recent preview frame. NOTE: Preview must be
   running.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
   <Return Value>
     Results object loaded with the analysis meta-data.
    */
AW_VIDEO_DECLARE(aw_video_results_t*) aw_video_camera_get_preview_frame(
  aw_video_t* aw_video,
  aw_video_camera_t* camera
);

/* <Function> aw_video_camera_start_capture
   <Description> Causes the camera to be clicked.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
   <Return Value>
     None
    */
AW_VIDEO_DECLARE(void) aw_video_camera_start_capture(
  aw_video_t* aw_video,
  aw_video_camera_t* camera
);

/* <Function> aw_video_camera_get_capture_frame
   <Description> Gets the most recent capture frame. NOTE: Capture method must
   have been called
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
   <Return Value>
     Results object loaded with the capture image data.
    */
AW_VIDEO_DECLARE(aw_video_results_t*) aw_video_camera_get_capture_frame(
  aw_video_t* aw_video,
  aw_video_camera_t* camera
);

/* <Function> aw_video_camera_get_status
   <Description> Get the status of an available camera.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
   <Return Value>
     Device status.
    */
AW_VIDEO_DECLARE(aw_video_device_status_t) aw_video_camera_get_status(
  aw_video_t* aw_video,
  aw_video_camera_t* camera
);

/* <Function> aw_video_camera_analyze_frame
   <Description> Feed a frame into the video library for analysis.
   <Parameters>
     aw_video - Library object pointer.
     camera - External Camera Object.
     image - Image buffer.
     image_size - Size of Image buffer.
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_analyze_frame(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_uint8_t* image,
  size_t image_size
);

/* <Function> aw_video_camera_analyze_frame_raw
   <Description> Feed a frame into the video library for analysis.  This
   function can only be used with an external camera.
   <Parameters>
     aw_video - Library object pointer.
     camera - External Camera Object.
     image - Image buffer.
     image_size - Size of Image buffer.
     format - A RAW Image format.
     width - Image width.
     height - Image height.
   <Return Value>
     Status code
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_analyze_frame_raw(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_uint8_t* image,
  size_t image_size,
  aw_video_image_format_t format,
  aw_int32_t width,
  aw_int32_t height
);

/* <Function> aw_video_camera_set_autocapture_mode
   <Description> Configure Autocapture mode.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
     autocapture_mode - Autocapture mode.
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_set_autocapture_mode(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_video_autocapture_mode_t autocapture_mode
);

/* <Function> aw_video_camera_read_autocapture_profile
   <Description> Read in a profile for Autocapture to use.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
     profile_buffer - Buffer containing the profile file.
     profile_buffer_size - Size of Buffer containing the profile file.
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_read_autocapture_profile(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_uint8_t* profile_buffer,
  size_t profile_buffer_size
);

/* <Function> aw_video_camera_set_autocapture_minimum_frame_count
   <Description> Set the minimum number of consecutive frames where a face
   must be compliant before AutoCapture will capture.  Can be
   combined with the minimum evaluation time and minimum
   compliance time.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
     min_frame_count - Number of compliant frames in a row before triggering
                       autocapture.  Must be greater than or equal to 1. 
                       Default is 3 frames.
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_set_autocapture_minimum_frame_count(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_uint32_t min_frame_count
);

/* <Function> aw_video_camera_set_autocapture_minimum_evaluation_time
   <Description> Set the minimum amount of time where a face must be present
   in consecutive frames before AutoCapture will capture.  Can
   be combined with the minimum frame count and minimum
   compliance time.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
     min_evaluation_time - Number of seconds where a face must be present
                           before AutoCapture will capture.  Must be greater
                           than or equal to 0.  Default is 0.0 seconds.
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_set_autocapture_minimum_evaluation_time(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_double_t min_evaluation_time
);

/* <Function> aw_video_camera_set_autocapture_minimum_compliance_time
   <Description> Set the minimum amount of time where a face must be compliant
   in consecutive frames before AutoCapture will capture.  Can
   be combined with the minimum frame count and minimum
   evaluation time.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
     min_compliance_time - Number of seconds where a face must be compliant
                           before AutoCapture will capture.  Must be greater
                           than or equal to 0.  Default is 0.0 seconds.
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_set_autocapture_minimum_compliance_time(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_double_t min_compliance_time
);

/* <Function> aw_video_camera_enable_algorithm
   <Description> Configure Algorithms to be on or off.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
     algorithm - Algorithm to enable or disable.
     enable - True for on.  False for off.
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_enable_algorithm(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_video_algorithm_t algorithm,
  aw_bool_t enable
);

/* <Function> aw_video_camera_set_algorithm_scoring_mode
   <Description> Configure the Scoring Mode for all Algorithms.  The default
   mode for all algorithms is CUMULATIVE mode.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
     scoring_mode - Scoring mode.
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_set_algorithm_scoring_mode(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_video_scoring_mode_t scoring_mode
);

/* <Function> aw_video_camera_set_algorithm_model_path
   <Description> Set the model path for the algorithm.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
     algorithm - Algorithm to push the score to.
     model_path - Model path.
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_set_algorithm_model_path(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_video_algorithm_t algorithm,
  const aw_char_t* model_path
);

/* <Function> aw_video_camera_push_algorithm_score
   <Description> Push an Algorithm score into the Algorithm before it begins
   computations.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
     algorithm - Algorithm to push the score to.
     score - Score to use as a base for the specified Algorithm.
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_push_algorithm_score(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_video_algorithm_t algorithm,
  aw_double_t score
);

/* <Function> aw_video_camera_enable_algorithm_reset
   <Description> Enable reseting Algorithms' data when an Algorithm is turned
   off.  The default value is true.  Algorithms are still reset
   when a new preview session is started regardless of this
   setting.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
     enable - Enable or disable the reseting of Algorithm data when an
              Algorithm is turned off.  True will clear Algorithm data when
              they are disabled.  False will preserve Algorithm data when they
              are disabled.
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_enable_algorithm_reset(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_bool_t enable
);

/* <Function> aw_video_camera_enable_face_event
   <Description> Configure which events to turn on or off for Event Detection.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
     face_event - Event to turn on or off.
     on - True for on.  False for off.
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_enable_face_event(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_video_face_event_t face_event,
  aw_bool_t on
);

/* <Function> aw_video_camera_enable_frame_tag
   <Description> Enable or disable a frame meta data tag on all subsequent
   frames analyzed.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
     frame_tag - Frame meta data tag.
     on - True for on.  False for off.
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_enable_frame_tag(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_video_frame_tag_t frame_tag,
  aw_bool_t on
);

/* <Function> aw_video_camera_set_timestamp
   <Description> Set the timestamp for the next frame passed in via the
   Analyze Frame or Analyze Frame Raw function.
   			Setting frame timestamps is only applicable to Synchronous
   External Cameras.
   			Timestamps are recommended to start at 0.0 with the first
   frame and required to increase for each subsequent Analyze
   Frame or Analyze Frame Raw call.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
     timestamp - The timestamp for the next frame to be passed in via Analyze
                 Frame or Analyze Frame Raw.  This is measured in seconds.
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_camera_set_timestamp(
  aw_video_t* aw_video,
  aw_video_camera_t* camera,
  aw_double_t timestamp
);

/* <Function> aw_video_camera_destroy
   <Description> Destroys the camera object.
   <Parameters>
     aw_video - Library object pointer.
     camera - Camera object.
   <Return Value>
     None
    */
AW_VIDEO_DECLARE(void) aw_video_camera_destroy(
  aw_video_t* aw_video,
  aw_video_camera_t* camera
);

/* <Function> aw_video_set_preview_callback
   <Description> Sets the preview_callback.
   <Parameters>
     aw_video - Library object pointer.
     preview_callback - Callback used to send preview frames up to the user.
     private_data - Private data used to determine callback context.
   <Return Value>
     Error code if an error was encountered.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_set_preview_callback(
  aw_video_t* aw_video,
  aw_video_preview_callback_t* preview_callback,
  void* private_data
);

/* <Function> aw_video_set_capture_callback
   <Description> Sets the capture_callback.
   <Parameters>
     aw_video - Library object pointer.
     capture_callback - Callback used to get the capture frame up to the user.
     private_data - Private data used to determine callback context.
   <Return Value>
     Error code if an error was encountered.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_set_capture_callback(
  aw_video_t* aw_video,
  aw_video_capture_callback_t* capture_callback,
  void* private_data
);

/* <Function> aw_video_set_device_status_callback
   <Description> Sets the device_status_callback.
   <Parameters>
     aw_video - Library object pointer.
     device_status_callback - Callback used to send device status up to the
                              user.
     private_data - Private data used to determine callback context.
   <Return Value>
     Error code if an error was encountered.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_set_device_status_callback(
  aw_video_t* aw_video,
  aw_video_device_status_callback_t* device_status_callback,
  void* private_data
);

/* <Function> aw_video_create_external_camera_config
   <Description> Creates a new external camera configuration
   <Parameters>
     aw_video - Library object pointer.
   <Return Value>
     Configuration handle.
    */
AW_VIDEO_DECLARE(aw_video_external_camera_config_t*) aw_video_create_external_camera_config(
  aw_video_t* aw_video
);

/* <Function> aw_video_external_camera_config_add_resolution
   <Description> Add a resolution to the external camera configuration.
   <Parameters>
     aw_video - Library object pointer.
     config_handle - External Camera Configuration handle.
     width - Width
     height - Height
   <Return Value>
     Error code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_external_camera_config_add_resolution(
  aw_video_t* aw_video,
  aw_video_external_camera_config_t* config_handle,
  aw_uint32_t width,
  aw_uint32_t height
);

/* <Function> aw_video_external_camera_config_enable_synchronous_analysis
   <Description> Enable or disable Synchronous Analysis.  When enabled, the
   External Camera created will return from Analyze Frame or
   Analyze Frame Raw after a full analysis has been done. 
   Requires an interframe time be set.  Disabled by default."
   <Parameters>
     aw_video - Library object pointer.
     config_handle - External Camera Configuration handle.
     enable - On or off.
   <Return Value>
     Error code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_external_camera_config_enable_synchronous_analysis(
  aw_video_t* aw_video,
  aw_video_external_camera_config_t* config_handle,
  aw_bool_t enable
);

/* <Function> aw_video_external_camera_config_destroy
   <Description> Destroys the external camera configuration.
   <Parameters>
     aw_video - Library object pointer.
     config_handle - Configuration handle.
   <Return Value>
     None
    */
AW_VIDEO_DECLARE(void) aw_video_external_camera_config_destroy(
  aw_video_t* aw_video,
  aw_video_external_camera_config_t* config_handle
);

/* <Function> aw_video_create_external_camera_from_config
   <Description> Using an External Camera Config, create a new External
   Camera.
   <Parameters>
     aw_video - Library object pointer.
     config_handle - Configuration handle.
   <Return Value>
     External Camera object.
    */
AW_VIDEO_DECLARE(aw_video_camera_t*) aw_video_create_external_camera_from_config(
  aw_video_t* aw_video,
  aw_video_external_camera_config_t* config_handle
);

/* Analysis Results */


/* <Function> aw_video_results_get_preface
   <Description> Get the preface object related to this set of analysis
   results.  The life of the preface object is tied directly to
   the results object it came from.  Do not explicitly destroy
   the preface object returned by this function.
   <Parameters>
     aw_video - Library object pointer.
     results_handle - Results handle.
   <Return Value>
     Preface object.
    */
AW_VIDEO_DECLARE(aw_preface_t*) aw_video_results_get_preface(
  aw_video_t* aw_video,
  aw_video_results_t* results_handle
);

/* <Function> aw_video_results_get_frame_id
   <Description> Get the ID number for the frame analyzed in this Results
   object.
   <Parameters>
     aw_video - Library object pointer.
     results_handle - Results handle.
   <Return Value>
     Frame ID assigned to the frame contained in this Results object.  Only
     frames analyzed by PreFace receive an ID.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_results_get_frame_id(
  aw_video_t* aw_video,
  aw_video_results_t* results_handle
);

/* <Function> aw_video_results_get_autocapture_status
   <Description> Get the autocapture results from the results handle.
   <Parameters>
     aw_video - Library object pointer.
     results_handle - Results handle.
   <Return Value>
     0 - Not Capturing; 1 - Capturing
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_results_get_autocapture_status(
  aw_video_t* aw_video,
  aw_video_results_t* results_handle
);

/* <Function> aw_video_results_get_face_event_score
   <Description> Get the event detection score for a particular event.
   <Parameters>
     aw_video - Library object pointer.
     results_handle - Results handle.
     face_event - Event to get the score of.
   <Return Value>
     Score for the event.  -1.0 indicates the score is not available.  Scores
     range from 0.0 to 100.0.
    */
AW_VIDEO_DECLARE(aw_double_t) aw_video_results_get_face_event_score(
  aw_video_t* aw_video,
  aw_video_results_t* results_handle,
  aw_video_face_event_t face_event
);

/* <Function> aw_video_results_get_algorithm_score
   <Description> Get the score for the specified Spoof Detection Algorithm.
   <Parameters>
     aw_video - Library object pointer.
     results_handle - Results handle.
     algorithm - Spoof Detection Algorithm to get the score from.
   <Return Value>
     Score for the specified Spoof Detection Algorithm.
    */
AW_VIDEO_DECLARE(aw_double_t) aw_video_results_get_algorithm_score(
  aw_video_t* aw_video,
  aw_video_results_t* results_handle,
  aw_video_algorithm_t algorithm
);

/* <Function> aw_video_results_get_autocapture_feedback
   <Description> Get a list of codes detailing the results of the autocapture
   algorithm's analysis.
   <Parameters>
     aw_video - Library object pointer.
     results_handle - Results handle.
     autocapture_feedback_codes_size - Size of List of autocapture_feedback
                                       enumerated values explaining the status
                                       of autocapture.
   <Return Value>
     List of autocapture_feedback enumerated values explaining the status of
     autocapture.
    */
AW_VIDEO_DECLARE(aw_video_autocapture_feedback_t*) aw_video_results_get_autocapture_feedback(
  aw_video_t* aw_video,
  aw_video_results_t* results_handle,
  size_t* autocapture_feedback_codes_size
);

/* <Function> aw_video_results_get_face_event_feedback
   <Description> Get a list of codes detailing feedback for the event
   detection algorithm.
   <Parameters>
     aw_video - Library object pointer.
     results_handle - Results handle.
     event_detection_feedback_codes_size - Size of List of detection_feedback
                                           enumerated values explaining the
                                           status of the event detection
                                           algorithm.
   <Return Value>
     List of detection_feedback enumerated values explaining the status of the
     event detection algorithm.
    */
AW_VIDEO_DECLARE(aw_video_detection_feedback_t*) aw_video_results_get_face_event_feedback(
  aw_video_t* aw_video,
  aw_video_results_t* results_handle,
  size_t* event_detection_feedback_codes_size
);

/* <Function> aw_video_results_get_algorithm_feedback
   <Description> Get a list of codes detailing feedback for the specified
   Spoof Detection Algorithm.
   <Parameters>
     aw_video - Library object pointer.
     results_handle - Results handle.
     algorithm - Spoof Detection Algorithm to get feedback from.
     spoof_detection_feedback_codes_size - Size of List of detection_feedback
                                           enumerated values explaining the
                                           status of the specified Spoof
                                           Detection Algorithm.
   <Return Value>
     List of detection_feedback enumerated values explaining the status of the
     specified Spoof Detection Algorithm.
    */
AW_VIDEO_DECLARE(aw_video_detection_feedback_t*) aw_video_results_get_algorithm_feedback(
  aw_video_t* aw_video,
  aw_video_results_t* results_handle,
  aw_video_algorithm_t algorithm,
  size_t* spoof_detection_feedback_codes_size
);

/* <Function> aw_video_results_get_autocapture_frame_list
   <Description> Get the list of the frame IDs that AutoCapture has processed.
   <Parameters>
     aw_video - Library object pointer.
     results_handle - Results handle.
     processed_frame_list_size - Size of List of the frame IDs processed by
                                 AutoCapture.
   <Return Value>
     List of the frame IDs processed by AutoCapture.
    */
AW_VIDEO_DECLARE(aw_int32_t*) aw_video_results_get_autocapture_frame_list(
  aw_video_t* aw_video,
  aw_video_results_t* results_handle,
  size_t* processed_frame_list_size
);

/* <Function> aw_video_results_get_event_detection_frame_list
   <Description> Get the list of the frame IDs that Event Detection has
   processed.
   <Parameters>
     aw_video - Library object pointer.
     results_handle - Results handle.
     processed_frame_list_size - Size of List of the frame IDs processed by
                                 Event Detection.
   <Return Value>
     List of the frame IDs processed by Event Detection.
    */
AW_VIDEO_DECLARE(aw_int32_t*) aw_video_results_get_event_detection_frame_list(
  aw_video_t* aw_video,
  aw_video_results_t* results_handle,
  size_t* processed_frame_list_size
);

/* <Function> aw_video_results_get_algorithm_frame_list
   <Description> Get the list of frame IDs that an Algorithm has processed.
   <Parameters>
     aw_video - Library object pointer.
     results_handle - Results handle.
     algorithm - Enabled Algorithm.
     processed_frame_list_size - Size of List of the frame IDs processed by
                                 the specifed Algorithm.
   <Return Value>
     List of the frame IDs processed by the specifed Algorithm.
    */
AW_VIDEO_DECLARE(aw_int32_t*) aw_video_results_get_algorithm_frame_list(
  aw_video_t* aw_video,
  aw_video_results_t* results_handle,
  aw_video_algorithm_t algorithm,
  size_t* processed_frame_list_size
);

/* <Function> aw_video_results_get_frame_timestamp
   <Description> Get the timestamp for the frame contained in the results
   object.
   <Parameters>
     aw_video - Library object pointer.
     results_handle - Results handle.
   <Return Value>
     The timestamp in terms of seconds.
    */
AW_VIDEO_DECLARE(aw_double_t) aw_video_results_get_frame_timestamp(
  aw_video_t* aw_video,
  aw_video_results_t* results_handle
);

/* <Function> aw_video_results_destroy
   <Description> Releases the specified results object.
   <Parameters>
     aw_video - Library object pointer.
     results_handle - The handle to a results object.
   <Return Value>
     None
    */
AW_VIDEO_DECLARE(void) aw_video_results_destroy(
  aw_video_t* aw_video,
  aw_video_results_t* results_handle
);

/* <Function> aw_video_get_autocapture_feedback_from_profile
   <Description> Get the list of autocapture feedback values that can
   potentially occur for a given profile.
   <Parameters>
     aw_video - Library object pointer.
     profile - Profile file as a byte buffer.
     profile_size - Size of Profile file as a byte buffer.
     feedback_list_size - Size of List of autocapture feedback values that can
                          occur using this profile.
   <Return Value>
     List of autocapture feedback values that can occur using this profile.
    */
AW_VIDEO_DECLARE(aw_video_autocapture_feedback_t*) aw_video_get_autocapture_feedback_from_profile(
  aw_video_t* aw_video,
  aw_uint8_t* profile,
  size_t profile_size,
  size_t* feedback_list_size
);

/* Camera Management */

/* <Function> aw_video_get_camera_list
   <Description> Gets the list of cameras currently connected to the computer.
   <Parameters>
     aw_video - Library object pointer.
     camera_list_size - Size of List of cameras currently connected.
   <Return Value>
     List of cameras currently connected.
    */
AW_VIDEO_DECLARE(aw_video_camera_t**) aw_video_get_camera_list(
  aw_video_t* aw_video,
  size_t* camera_list_size
);

/* <Function> aw_video_refresh_camera_list
   <Description> Refreshes the list of cameras currently connected to the
   computer. Cannot be called while a Camera is open as this
   will invalidate all current camera objects.
   <Parameters>
     aw_video - Library object pointer.
   <Return Value>
     Status code of the function called.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_refresh_camera_list(
  aw_video_t* aw_video
);

/* Face Detection Analysis Settings */

/* <Function> aw_video_get_face_detection_min_size
   <Description> Get the current face detection minimum search size.
   <Parameters>
     aw_video - Library object pointer.
   <Return Value>
     Value on (0, 1.0] indicating the minimum size of face to search for.
    */
AW_VIDEO_DECLARE(aw_double_t) aw_video_get_face_detection_min_size(
  aw_video_t* aw_video
);

/* <Function> aw_video_get_face_detection_max_size
   <Description> Get the current face detection maximum search size.
   <Parameters>
     aw_video - Library object pointer.
   <Return Value>
     Value on (0, 1.0] indicating the maximum size of face to search for.
    */
AW_VIDEO_DECLARE(aw_double_t) aw_video_get_face_detection_max_size(
  aw_video_t* aw_video
);

/* <Function> aw_video_set_face_detection_size
   <Description> Set the face detection search size for video analysis.
   <Parameters>
     aw_video - Library object pointer.
     minimum - Minimum search size. (0.0, 1.0]
     maximum - Maximum search size. (0.0, 1.0]
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_set_face_detection_size(
  aw_video_t* aw_video,
  aw_double_t minimum,
  aw_double_t maximum
);

/* <Function> aw_video_get_face_detection_sensitivity
   <Description> Get the current face detection sensitivity.
   <Parameters>
     aw_video - Library object pointer.
   <Return Value>
     Value on (0, 1.0] indicating the search sensitivity.
    */
AW_VIDEO_DECLARE(aw_double_t) aw_video_get_face_detection_sensitivity(
  aw_video_t* aw_video
);

/* <Function> aw_video_set_face_detection_sensitivity
   <Description> Set the face detection sensitivity for video analysis.
   <Parameters>
     aw_video - Library object pointer.
     sensitivity - Sensitivity search size. (0.0, 1.0]
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_set_face_detection_sensitivity(
  aw_video_t* aw_video,
  aw_double_t sensitivity
);

/* <Function> aw_video_get_face_detection_granularity
   <Description> Get the current face detection granularity.
   <Parameters>
     aw_video - Library object pointer.
   <Return Value>
     Value on (0, 1.0] indicating the search granularity.
    */
AW_VIDEO_DECLARE(aw_double_t) aw_video_get_face_detection_granularity(
  aw_video_t* aw_video
);

/* <Function> aw_video_set_face_detection_granularity
   <Description> Set the face detection granularity for video analysis.
   <Parameters>
     aw_video - Library object pointer.
     granularity - Granularity search size. (0.0, 1.0]
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_set_face_detection_granularity(
  aw_video_t* aw_video,
  aw_double_t granularity
);

/* <Function> aw_video_get_face_detection_mode
   <Description> Get the current face detection mode.
   <Parameters>
     aw_video - Library object pointer.
   <Return Value>
     Face detection mode.
    */
AW_VIDEO_DECLARE(aw_video_face_detection_mode_t) aw_video_get_face_detection_mode(
  aw_video_t* aw_video
);

/* <Function> aw_video_set_face_detection_mode
   <Description> Set the face detection mode for video analysis.
   <Parameters>
     aw_video - Library object pointer.
     face_detection_mode - Face detection mode.
   <Return Value>
     Status code.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_set_face_detection_mode(
  aw_video_t* aw_video,
  aw_video_face_detection_mode_t face_detection_mode
);

/* Error Handling */

/* <Function> aw_video_get_last_error
   <Description> Returns the status code of the last function called.
   <Parameters>
     aw_video - Library object pointer.
   <Return Value>
     Status code of the last function called.
    */
AW_VIDEO_DECLARE(aw_int32_t) aw_video_get_last_error(
  aw_video_t* aw_video
);

/* <Function> aw_video_get_last_error_details
   <Description> Returns the status code of the last function called.
   <Parameters>
     aw_video - Library object pointer.
   <Return Value>
     Details of the last error that occurred.
    */
AW_VIDEO_DECLARE(const aw_char_t*) aw_video_get_last_error_details(
  aw_video_t* aw_video
);



#ifdef __cplusplus
}
#endif

#endif /* _AW_VIDEO_H_ */

